{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8db2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 1. Imports\n",
    "# -------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24a3356",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Raw dataset not found at: /Users/benjaminnguyen/Employee_attrition/data/raw/employee_data.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m file_path = os.path.join(raw_folder, \u001b[33m\"\u001b[39m\u001b[33memployee_data.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(file_path):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRaw dataset not found at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m df = pd.read_csv(file_path)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRaw dataset loaded.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Raw dataset not found at: /Users/benjaminnguyen/Employee_attrition/data/raw/employee_data.csv"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 2. Set Paths\n",
    "# -------------------------\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "raw_folder = os.path.join(project_root, \"data\", \"raw\")\n",
    "processed_folder = os.path.join(project_root, \"data\", \"processed\")\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "file_path = os.path.join(raw_folder, \"employee_data.csv\")\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Raw dataset not found at: {file_path}\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Raw dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 3. Target Variable\n",
    "# -------------------------\n",
    "target = \"Attrition\"\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"Target '{target}' not found in dataset.\")\n",
    "\n",
    "# Encode target: 1 = Yes (Attrition), 0 = No\n",
    "y = df[target].map({'Yes': 1, 'No': 0})\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "print(f\"Target distribution:\\n{y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dfce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 4. Identify Column Types\n",
    "# -------------------------\n",
    "numeric_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "print(f\"Numeric cols: {numeric_cols}\")\n",
    "print(f\"Categorical cols: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 5. Outlier Handling\n",
    "# -------------------------\n",
    "for col in numeric_cols:\n",
    "    Q1 = X[col].quantile(0.25)\n",
    "    Q3 = X[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "    X[col] = np.clip(X[col], lower, upper)  # cap outliers\n",
    "\n",
    "# Visualize distributions by target\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.violinplot(x=y, y=X[col])\n",
    "    plt.title(f\"{col} distribution by Attrition\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 6. Class Imbalance Check\n",
    "# -------------------------\n",
    "print(\"Class distribution after encoding:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 7. Missing Value Indicators\n",
    "# -------------------------\n",
    "missing_cols = [col for col in X.columns if X[col].isnull().sum() > 0]\n",
    "for col in missing_cols:\n",
    "    X[col + \"_missing\"] = X[col].isnull().astype(int)\n",
    "print(f\"Missing indicators added for: {missing_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 8. Impute, Encode, Scale\n",
    "# -------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"  # keep missing indicators\n",
    ")\n",
    "\n",
    "X_clean = preprocessor.fit_transform(X)\n",
    "\n",
    "# Build DataFrame with correct column names\n",
    "encoded_cat_cols = preprocessor.named_transformers_[\"cat\"][\"encoder\"].get_feature_names_out(categorical_cols)\n",
    "clean_feature_names = numeric_cols + list(encoded_cat_cols) + [col for col in X.columns if col.endswith(\"_missing\")]\n",
    "X_clean_df = pd.DataFrame(X_clean, columns=clean_feature_names)\n",
    "\n",
    "print(f\"Final cleaned shape: {X_clean_df.shape}\")\n",
    "X_clean_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 9. Train/Test Split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean_df, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053bf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 10. Save Processed Data\n",
    "# -------------------------\n",
    "X_train.to_csv(os.path.join(processed_folder, \"train.csv\"), index=False)\n",
    "X_test.to_csv(os.path.join(processed_folder, \"test.csv\"), index=False)\n",
    "y_train.to_csv(os.path.join(processed_folder, \"y_train.csv\"), index=False)\n",
    "y_test.to_csv(os.path.join(processed_folder, \"y_test.csv\"), index=False)\n",
    "\n",
    "print(\"Processed train/test datasets saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
